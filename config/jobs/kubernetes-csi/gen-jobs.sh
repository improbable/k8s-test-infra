#! /bin/bash -e
# Copyright 2019 The Kubernetes Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# The presubmit jobs for the different Kubernetes-CSI repos are all
# the same except for the repo name. As Prow has no way of specifying
# the same job for multiple repos and manually copy-and-paste would be
# tedious, this script is used instead to generate them.

base="$(dirname $0)"

# All kubernetes-csi repos for which Prow gets configured.
repos="
cluster-driver-registrar
csi-driver-host-path
csi-release-tools
"

# Currently disabled because of https://github.com/kubernetes/test-infra/issues/11703,
# see https://github.com/kubernetes/test-infra/pull/11715#issuecomment-472164071
# csi-driver-fibre-channel
# csi-driver-image-populator
# csi-driver-iscsi
# csi-driver-nfs
# csi-lib-fc
# csi-lib-iscsi
# csi-lib-utils
# csi-test
# external-attacher
# external-provisioner
# external-resizer
# external-snapshotter
# livenessprobe
# node-driver-registrar


# All branches that do *not* support Prow testing. All new branches
# are expected to have that support, therefore these list should be
# fixed. By blacklisting old branches we can avoid Prow config
# changes each time a new branch gets created.
skip_branches_cluster_driver_registrar='^(release-1.0)$'
skip_branches_csi_lib_utils='^(release-0.1|release-0.2)$'
skip_branches_csi_test='^(release-0.3|release-1.0|saad-ali-patch-1|saad-ali-patch-2|v0.1.0|v0.2.0)$'
skip_branches_external_attacher='^(release-0.2.0|release-0.3.0|release-0.4|release-1.0|saad-ali-patch-1|saad-ali-patch-2|saad-ali-patch-3|v0.1.0)$'
skip_branches_external_provisioner='^(lpabon-patch-1|release-0.2.0|release-0.3.0|release-0.4|release-1.0|saad-ali-patch-1|saad-ali-patch-2|v0.1.0)$'
skip_branches_external_snapshotter='^(errorhandling|k8s_1.12.0-beta.1|release-0.4|release-1.0|revert-72-pvclister|saad-ali-patch-1|saad-ali-patch-2|test-yang|updateSize)$'
skip_branches_livenessprobe='^(re|release-0.4|release-1.0|saad-ali-patch-1|saad-ali-patch-2|saad-ali-patch-3|saad-ali-patch-4)$'
skip_branches_node_driver_registrar='^(release-1.0)$'

skip_branches () {
    eval echo \\\"\$skip_branches_$(echo $1 | tr - _)\\\" | grep -v '""'
}

find "$base" -name '*.yaml' -exec grep -q 'generated by gen-jobs.sh' '{}' \; -delete



for repo in $repos; do
    # echo "skip_branches_$repo=^($(echo $(git ls-remote --heads https://github.com/kubernetes-csi/$repo | grep refs/heads | sed -e 's;.*refs/heads/;;' | grep -v master) | tr ' ' '|'))"

    mkdir -p "$base/$repo"
    cat >"$base/$repo/$repo.yaml" <<EOF
# generated by gen-jobs.sh, do not edit manually

presubmits:
  kubernetes-csi/$repo:
  - name: pull-sig-storage-$repo-kubernetes-1-13
    # Experimental job, explicitly needs to be started with /test.
    always_run: false
    decorate: true
    skip_report: false
    skip_branches: [$(skip_branches $repo)]
    labels:
      preset-service-account: "true"
      preset-dind-enabled: "true"
      preset-kind-volume-mounts: "true"
    spec:
      containers:
      # We need this image because it has Docker in Docker and go.
      - image: gcr.io/k8s-testimages/kubekins-e2e:v20190301-76bc03340-master
        command:
        - runner.sh
        args:
        - ./.prow.sh
        env:
        # We pick some version for which there are pre-built images for kind.
        # Update only when the newer version is known to not cause issues,
        # otherwise presubmit jobs may start to fail for reasons that are
        # unrelated to the PR.
        #
        # See ci-kubernetes-csi-stable-on-kubernetes-1-13 for testing on the
        # latest Kubernetes 1.13.x.
        - name: CSI_PROW_KUBERNETES_VERSION
          value: "1.13.3"
        # docker-in-docker needs privileged mode
        securityContext:
          privileged: true
        resources:
          requests:
            cpu: 2000m
  - name: pull-sig-storage-$repo-kubernetes-master
    # Experimental job, explicitly needs to be started with /test.
    always_run: false
    decorate: true
    skip_report: false
    labels:
      preset-service-account: "true"
      preset-dind-enabled: "true"
      preset-bazel-remote-cache-enabled: "true"
      preset-kind-volume-mounts: "true"
    spec:
      containers:
      # We need this image because it has Docker in Docker and go.
      - image: gcr.io/k8s-testimages/kubekins-e2e:v20190301-76bc03340-master
        command:
        - runner.sh
        args:
        - ./.prow.sh
        env:
        - name: CSI_PROW_KUBERNETES_VERSION
          value: "latest"
        # docker-in-docker needs privileged mode
        securityContext:
          privileged: true
      resources:
        requests:
          # these are both a bit below peak usage during build
          # this is mostly for building kubernetes
          memory: "9000Mi"
          # during the tests more like 3-20m is used
          cpu: 2000m
EOF
done

# The csi-driver-host-path repo contains different deployments. We
# test those against different Kubernetes releases at regular
# intervals to detect regressions in Kubernetes. Should not happen as
# Kubernetes itself (at least currently) runs the same tests, but
# better safe than sorry...
cat >>"$base/csi-driver-host-path/csi-driver-host-path.yaml" <<EOF

periodics:
- interval: 6h
  name: ci-kubernetes-csi-stable-on-kubernetes-master
  decorate: true
  extra_refs:
  # TODO: replace with kubernetes-csi/csi-driver-host-path master once branch prow is merged
  - org: pohly
    repo: csi-driver-host-path
    base_ref: prow
  labels:
    preset-service-account: "true"
    preset-dind-enabled: "true"
    preset-bazel-remote-cache-enabled: "true"
    preset-kind-volume-mounts: "true"
  spec:
    containers:
    # We need this image because it has Docker in Docker and go.
    - image: gcr.io/k8s-testimages/kubekins-e2e:v20190301-76bc03340-master
      command:
      - runner.sh
      args:
      - ./.prow.sh
      env:
      # The current stable set of Kubernetes-CSI components is meant to be compatible
      # with future Kubernetes, except for alpha features. Those therefore do not get
      # tested.
      - name: CSI_PROW_KUBERNETES_VERSION
        value: "latest"
      - name: CSI_PROW_BUILD_JOB
        value: "false"
      - name: CSI_PROW_DEPLOYMENT
        value: "kubernetes-1.13"
      - name: CSI_PROW_E2E_ALPHA_FOCUS
        value: none
      # docker-in-docker needs privileged mode
      securityContext:
        privileged: true
    resources:
      requests:
        # these are both a bit below peak usage during build
        # this is mostly for building kubernetes
        memory: "9000Mi"
        # during the tests more like 3-20m is used
        cpu: 2000m

- interval: 6h
  name: ci-kubernetes-csi-stable-on-kubernetes-1-13
  decorate: true
  extra_refs:
  # TODO: replace with kubernetes-csi/csi-driver-host-path master once branch prow is merged
  - org: pohly
    repo: csi-driver-host-path
    base_ref: prow
  labels:
    preset-service-account: "true"
    preset-dind-enabled: "true"
    preset-bazel-remote-cache-enabled: "true"
    preset-kind-volume-mounts: "true"
  spec:
    containers:
    # We need this image because it has Docker in Docker and go.
    - image: gcr.io/k8s-testimages/kubekins-e2e:v20190301-76bc03340-master
      command:
      - runner.sh
      args:
      - ./.prow.sh
      env:
      # The current stable set of Kubernetes-CSI components is meant to be compatible
      # with Kubernetes 1.13.x, including alpha features.
      - name: CSI_PROW_KUBERNETES_VERSION
        value: "release-1.13"
      - name: CSI_PROW_BUILD_JOB
        value: "false"
      - name: CSI_PROW_DEPLOYMENT
        value: "kubernetes-1.13"
      # docker-in-docker needs privileged mode
      securityContext:
        privileged: true
    resources:
      requests:
        # these are both a bit below peak usage during build
        # this is mostly for building kubernetes
        memory: "9000Mi"
        # during the tests more like 3-20m is used
        cpu: 2000m
EOF
